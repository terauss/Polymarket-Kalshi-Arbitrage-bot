//! Intelligent market discovery and matching system.
//!
//! This module handles the discovery of matching markets between Kalshi and Polymarket,
//! with support for caching, incremental updates, and parallel processing.

use anyhow::Result;
use futures_util::{stream, StreamExt};
use governor::{Quota, RateLimiter, state::NotKeyed, clock::DefaultClock, middleware::NoOpMiddleware};
use regex::Regex;
use std::sync::LazyLock;
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use std::num::NonZeroU32;
use std::sync::Arc;
use std::time::{SystemTime, UNIX_EPOCH};
use tokio::sync::Semaphore;
use tracing::{info, warn};

use crate::cache::TeamCache;
use crate::config::{LeagueConfig, get_league_configs, get_league_config};
use crate::kalshi::KalshiApiClient;
use crate::polymarket::GammaClient;
use crate::types::{MarketPair, MarketType, DiscoveryResult, KalshiMarket, KalshiEvent};

/// Max concurrent Gamma API requests
const GAMMA_CONCURRENCY: usize = 20;

/// Kalshi rate limit: 2 requests per second (very conservative - they rate limit aggressively)
/// Must be conservative because discovery runs many leagues/series in parallel
const KALSHI_RATE_LIMIT_PER_SEC: u32 = 2;

/// Max concurrent Kalshi API requests GLOBALLY across all leagues/series
/// This is the hard cap - prevents bursting even when rate limiter has tokens
const KALSHI_GLOBAL_CONCURRENCY: usize = 1;

/// Cache file path
const DISCOVERY_CACHE_PATH: &str = ".discovery_cache.json";

/// Cache TTL in seconds (2 hours - new markets appear every ~2 hours)
const CACHE_TTL_SECS: u64 = 2 * 60 * 60;

/// Task for parallel Gamma lookup
struct GammaLookupTask {
    event: Arc<KalshiEvent>,
    market: KalshiMarket,
    poly_slug: String,
    market_type: MarketType,
    league: String,
}

/// Type alias for Kalshi rate limiter
type KalshiRateLimiter = RateLimiter<NotKeyed, governor::state::InMemoryState, DefaultClock, NoOpMiddleware>;

/// Persistent cache for discovered market pairs
#[derive(Debug, Clone, Serialize, Deserialize)]
struct DiscoveryCache {
    /// Unix timestamp when cache was created
    timestamp_secs: u64,
    /// Cached market pairs
    pairs: Vec<MarketPair>,
    /// Set of known Kalshi market tickers (for incremental updates)
    known_kalshi_tickers: Vec<String>,
}

impl DiscoveryCache {
    fn new(pairs: Vec<MarketPair>) -> Self {
        let known_kalshi_tickers: Vec<String> = pairs.iter()
            .map(|p| p.kalshi_market_ticker.to_string())
            .collect();
        Self {
            timestamp_secs: current_unix_secs(),
            pairs,
            known_kalshi_tickers,
        }
    }

    fn is_expired(&self) -> bool {
        let now = current_unix_secs();
        now.saturating_sub(self.timestamp_secs) > CACHE_TTL_SECS
    }

    fn age_secs(&self) -> u64 {
        current_unix_secs().saturating_sub(self.timestamp_secs)
    }

    fn has_ticker(&self, ticker: &str) -> bool {
        self.known_kalshi_tickers.iter().any(|t| t == ticker)
    }
}

fn current_unix_secs() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_secs()
}

/// Market discovery and matching client for cross-platform market identification
pub struct DiscoveryClient {
    kalshi: Arc<KalshiApiClient>,
    gamma: Arc<GammaClient>,
    pub team_cache: Arc<TeamCache>,
    kalshi_limiter: Arc<KalshiRateLimiter>,
    kalshi_semaphore: Arc<Semaphore>,  // Global concurrency limit for Kalshi
    gamma_semaphore: Arc<Semaphore>,
}

impl DiscoveryClient {
    pub fn new(kalshi: KalshiApiClient, team_cache: TeamCache) -> Self {
        // Create token bucket rate limiter for Kalshi
        let quota = Quota::per_second(NonZeroU32::new(KALSHI_RATE_LIMIT_PER_SEC).unwrap());
        let kalshi_limiter = Arc::new(RateLimiter::direct(quota));

        Self {
            kalshi: Arc::new(kalshi),
            gamma: Arc::new(GammaClient::new()),
            team_cache: Arc::new(team_cache),
            kalshi_limiter,
            kalshi_semaphore: Arc::new(Semaphore::new(KALSHI_GLOBAL_CONCURRENCY)),
            gamma_semaphore: Arc::new(Semaphore::new(GAMMA_CONCURRENCY)),
        }
    }

    /// Load cache from disk (async)
    async fn load_cache() -> Option<DiscoveryCache> {
        let data = tokio::fs::read_to_string(DISCOVERY_CACHE_PATH).await.ok()?;
        serde_json::from_str(&data).ok()
    }

    /// Save cache to disk (async)
    async fn save_cache(cache: &DiscoveryCache) -> Result<()> {
        let data = serde_json::to_string_pretty(cache)?;
        tokio::fs::write(DISCOVERY_CACHE_PATH, data).await?;
        Ok(())
    }
    
    /// Discover all market pairs with caching support
    ///
    /// Strategy:
    /// 1. Try to load cache from disk
    /// 2. If cache exists and is fresh (<2 hours), use it directly
    /// 3. If cache exists but is stale, load it + fetch incremental updates
    /// 4. If no cache, do full discovery
    pub async fn discover_all(&self, leagues: &[&str]) -> DiscoveryResult {
        // Try to load existing cache
        let cached = Self::load_cache().await;

        match cached {
            Some(cache) if !cache.is_expired() => {
                // Cache is fresh - filter by enabled leagues and return
                let age = cache.age_secs();
                let pairs = filter_pairs_by_leagues(cache.pairs, leagues);
                info!("üìÇ Loaded {} pairs from cache (age: {}s){}",
                      pairs.len(), age,
                      if !leagues.is_empty() { format!(" [filtered to {:?}]", leagues) } else { String::new() });
                return DiscoveryResult {
                    pairs,
                    kalshi_events_found: 0,  // From cache
                    poly_matches: 0,
                    poly_misses: 0,
                    errors: vec![],
                };
            }
            Some(cache) => {
                // Cache is stale - do incremental discovery
                info!("üìÇ Cache expired (age: {}s), doing incremental refresh...", cache.age_secs());
                return self.discover_incremental(leagues, cache).await;
            }
            None => {
                // No cache - do full discovery
                info!("üìÇ No cache found, doing full discovery...");
            }
        }

        // Full discovery (no cache)
        let result = self.discover_full(leagues).await;

        // Save to cache
        if !result.pairs.is_empty() {
            let cache = DiscoveryCache::new(result.pairs.clone());
            if let Err(e) = Self::save_cache(&cache).await {
                warn!("Failed to save discovery cache: {}", e);
            } else {
                info!("üíæ Saved {} pairs to cache", result.pairs.len());
            }
        }

        result
    }

    /// Force full discovery (ignores cache)
    pub async fn discover_all_force(&self, leagues: &[&str]) -> DiscoveryResult {
        info!("üîÑ Forced full discovery (ignoring cache)...");
        let result = self.discover_full(leagues).await;

        // Save to cache
        if !result.pairs.is_empty() {
            let cache = DiscoveryCache::new(result.pairs.clone());
            if let Err(e) = Self::save_cache(&cache).await {
                warn!("Failed to save discovery cache: {}", e);
            } else {
                info!("üíæ Saved {} pairs to cache", result.pairs.len());
            }
        }

        result
    }

    /// Full discovery without cache
    async fn discover_full(&self, leagues: &[&str]) -> DiscoveryResult {
        let configs: Vec<_> = if leagues.is_empty() {
            get_league_configs()
        } else {
            leagues.iter()
                .filter_map(|l| get_league_config(l))
                .collect()
        };

        // Parallel discovery across all leagues
        let league_futures: Vec<_> = configs.iter()
            .map(|config| self.discover_league(config, None))
            .collect();

        let league_results = futures_util::future::join_all(league_futures).await;

        // Merge results
        let mut result = DiscoveryResult::default();
        for league_result in league_results {
            result.pairs.extend(league_result.pairs);
            result.poly_matches += league_result.poly_matches;
            result.errors.extend(league_result.errors);
        }
        result.kalshi_events_found = result.pairs.len();

        result
    }

    /// Incremental discovery - merge cached pairs with newly discovered ones
    async fn discover_incremental(&self, leagues: &[&str], cache: DiscoveryCache) -> DiscoveryResult {
        let configs: Vec<_> = if leagues.is_empty() {
            get_league_configs()
        } else {
            leagues.iter()
                .filter_map(|l| get_league_config(l))
                .collect()
        };

        // Discover with filter for known tickers
        let league_futures: Vec<_> = configs.iter()
            .map(|config| self.discover_league(config, Some(&cache)))
            .collect();

        let league_results = futures_util::future::join_all(league_futures).await;

        // Merge cached pairs with newly discovered ones
        let mut all_pairs = cache.pairs;
        let mut new_count = 0;

        for league_result in league_results {
            for pair in league_result.pairs {
                if !all_pairs.iter().any(|p| *p.kalshi_market_ticker == *pair.kalshi_market_ticker) {
                    all_pairs.push(pair);
                    new_count += 1;
                }
            }
        }

        if new_count > 0 {
            info!("üÜï Found {} new market pairs", new_count);

            // Update cache
            let new_cache = DiscoveryCache::new(all_pairs.clone());
            if let Err(e) = Self::save_cache(&new_cache).await {
                warn!("Failed to update discovery cache: {}", e);
            } else {
                info!("üíæ Updated cache with {} total pairs", all_pairs.len());
            }
        } else {
            info!("‚úÖ No new markets found, using {} cached pairs", all_pairs.len());

            // Just update timestamp to extend TTL
            let refreshed_cache = DiscoveryCache::new(all_pairs.clone());
            let _ = Self::save_cache(&refreshed_cache).await;
        }

        DiscoveryResult {
            pairs: all_pairs,
            kalshi_events_found: new_count,
            poly_matches: new_count,
            poly_misses: 0,
            errors: vec![],
        }
    }
    
    /// Discover all market types for a single league (PARALLEL)
    /// If cache is provided, only discovers markets not already in cache
    async fn discover_league(&self, config: &LeagueConfig, cache: Option<&DiscoveryCache>) -> DiscoveryResult {
        // Use esports discovery for leagues with poly_series_id
        if config.poly_series_id.is_some() {
            return self.discover_esports_league(config).await;
        }

        info!("üîç Discovering {} markets...", config.league_code);

        let market_types = [MarketType::Moneyline, MarketType::Spread, MarketType::Total, MarketType::Btts];

        // Parallel discovery across market types
        let type_futures: Vec<_> = market_types.iter()
            .filter_map(|market_type| {
                let series = self.get_series_for_type(config, *market_type)?;
                Some(self.discover_series(config, series, *market_type, cache))
            })
            .collect();

        let type_results = futures_util::future::join_all(type_futures).await;

        let mut result = DiscoveryResult::default();
        for (pairs_result, market_type) in type_results.into_iter().zip(market_types.iter()) {
            match pairs_result {
                Ok(pairs) => {
                    let count = pairs.len();
                    if count > 0 {
                        info!("  ‚úÖ {} {}: {} pairs", config.league_code, market_type, count);
                    }
                    result.poly_matches += count;
                    result.pairs.extend(pairs);
                }
                Err(e) => {
                    result.errors.push(format!("{} {}: {}", config.league_code, market_type, e));
                }
            }
        }

        result
    }
    
    fn get_series_for_type(&self, config: &LeagueConfig, market_type: MarketType) -> Option<&'static str> {
        match market_type {
            MarketType::Moneyline => Some(config.kalshi_series_game),
            MarketType::Spread => config.kalshi_series_spread,
            MarketType::Total => config.kalshi_series_total,
            MarketType::Btts => config.kalshi_series_btts,
        }
    }
    
    /// Discover markets for a specific series (PARALLEL Kalshi + Gamma lookups)
    /// If cache is provided, skips markets already in cache
    async fn discover_series(
        &self,
        config: &LeagueConfig,
        series: &str,
        market_type: MarketType,
        cache: Option<&DiscoveryCache>,
    ) -> Result<Vec<MarketPair>> {
        // Fetch Kalshi events
        {
            let _permit = self.kalshi_semaphore.acquire().await.map_err(|e| anyhow::anyhow!("semaphore closed: {}", e))?;
            self.kalshi_limiter.until_ready().await;
        }
        let events = self.kalshi.get_events(series, 50).await?;

        if events.is_empty() {
            return Ok(vec![]);
        }
        info!("  üì° {} {}: {} events from Kalshi", config.league_code, market_type, events.len());

        // PHASE 2: Parallel market fetching 
        let kalshi = self.kalshi.clone();
        let limiter = self.kalshi_limiter.clone();
        let semaphore = self.kalshi_semaphore.clone();

        // Parse events first, filtering out unparseable ones
        let parsed_events: Vec<_> = events.into_iter()
            .filter_map(|event| {
                let parsed = match parse_kalshi_event_ticker(&event.event_ticker) {
                    Some(p) => p,
                    None => {
                        warn!("  ‚ö†Ô∏è Could not parse event ticker {}", event.event_ticker);
                        return None;
                    }
                };
                Some((parsed, event))
            })
            .collect();

        // Execute market fetches with GLOBAL concurrency limit
        let market_results: Vec<_> = stream::iter(parsed_events)
            .map(|(parsed, event)| {
                let kalshi = kalshi.clone();
                let limiter = limiter.clone();
                let semaphore = semaphore.clone();
                let event_ticker = event.event_ticker.clone();
                async move {
                    let _permit = semaphore.acquire().await.ok();
                    // rate limit
                    limiter.until_ready().await;
                    let markets_result = kalshi.get_markets(&event_ticker).await;
                    (parsed, Arc::new(event), markets_result)
                }
            })
            .buffer_unordered(KALSHI_GLOBAL_CONCURRENCY * 2)  // Allow some buffering, semaphore is the real limit
            .collect()
            .await;

        // Collect all (event, market) pairs
        let mut event_markets = Vec::with_capacity(market_results.len() * 3);
        let mut cached_count = 0usize;
        for (parsed, event, markets_result) in market_results {
            match markets_result {
                Ok(markets) => {
                    for market in markets {
                        // Skip if already in cache
                        if let Some(c) = cache {
                            if c.has_ticker(&market.ticker) {
                                cached_count += 1;
                                continue;
                            }
                        }
                        event_markets.push((parsed.clone(), event.clone(), market));
                    }
                }
                Err(e) => {
                    warn!("  ‚ö†Ô∏è Failed to get markets for {}: {}", event.event_ticker, e);
                }
            }
        }

        if event_markets.is_empty() {
            if cached_count > 0 {
                info!("  ‚úÖ {} {}: {} markets (all cached)", config.league_code, market_type, cached_count);
            }
            return Ok(vec![]);
        }
        info!("  üîé {} {}: looking up {} new markets on Polymarket{}",
              config.league_code, market_type, event_markets.len(),
              if cached_count > 0 { format!(" ({} cached)", cached_count) } else { String::new() });

        // Parallel Gamma lookups with semaphore
        let lookup_futures: Vec<_> = event_markets
            .into_iter()
            .map(|(parsed, event, market)| {
                let poly_slug = self.build_poly_slug(config.poly_prefix, &parsed, market_type, &market);
                
                GammaLookupTask {
                    event,
                    market,
                    poly_slug,
                    market_type,
                    league: config.league_code.to_string(),
                }
            })
            .collect();
        
        // Execute lookups in parallel 
        let pairs: Vec<MarketPair> = stream::iter(lookup_futures)
            .map(|task| {
                let gamma = self.gamma.clone();
                let semaphore = self.gamma_semaphore.clone();
                async move {
                    let _permit = semaphore.acquire().await.ok()?;
                    match gamma.lookup_market(&task.poly_slug).await {
                        Ok(Some((yes_token, no_token))) => {
                            let team_suffix = extract_team_suffix(&task.market.ticker);
                            Some(MarketPair {
                                pair_id: format!("{}-{}", task.poly_slug, task.market.ticker).into(),
                                league: task.league.into(),
                                market_type: task.market_type,
                                description: format!("{} - {}", task.event.title, task.market.title).into(),
                                kalshi_event_ticker: task.event.event_ticker.clone().into(),
                                kalshi_market_ticker: task.market.ticker.into(),
                                poly_slug: task.poly_slug.into(),
                                poly_yes_token: yes_token.into(),
                                poly_no_token: no_token.into(),
                                line_value: task.market.floor_strike,
                                team_suffix: team_suffix.map(|s| s.into()),
                            })
                        }
                        Ok(None) => None,
                        Err(e) => {
                            warn!("  ‚ö†Ô∏è Gamma lookup failed for {}: {}", task.poly_slug, e);
                            None
                        }
                    }
                }
            })
            .buffer_unordered(GAMMA_CONCURRENCY)
            .filter_map(|x| async { x })
            .collect()
            .await;

        if !pairs.is_empty() {
            info!("  ‚úÖ {} {}: matched {} pairs", config.league_code, market_type, pairs.len());
        }

        Ok(pairs)
    }
    
    /// Build Polymarket slug from Kalshi event data
    fn build_poly_slug(
        &self,
        poly_prefix: &str,
        parsed: &ParsedKalshiTicker,
        market_type: MarketType,
        market: &KalshiMarket,
    ) -> String {
        // Convert Kalshi team codes to Polymarket codes using cache
        let poly_team1 = self.team_cache
            .kalshi_to_poly(poly_prefix, &parsed.team1)
            .unwrap_or_else(|| parsed.team1.to_lowercase());
        let poly_team2 = self.team_cache
            .kalshi_to_poly(poly_prefix, &parsed.team2)
            .unwrap_or_else(|| parsed.team2.to_lowercase());

        // Convert date from "25DEC27" to "2025-12-27"
        let date_str = kalshi_date_to_iso(&parsed.date);

        // Base slug: league-team1-team2-date
        let base = format!("{}-{}-{}-{}", poly_prefix, poly_team1, poly_team2, date_str);

        match market_type {
            MarketType::Moneyline => {
                if let Some(suffix) = extract_team_suffix(&market.ticker) {
                    if suffix.to_lowercase() == "tie" {
                        format!("{}-draw", base)
                    } else {
                        let poly_suffix = self.team_cache
                            .kalshi_to_poly(poly_prefix, &suffix)
                            .unwrap_or_else(|| suffix.to_lowercase());
                        format!("{}-{}", base, poly_suffix)
                    }
                } else {
                    base
                }
            }
            MarketType::Spread => {
                if let Some(floor) = market.floor_strike {
                    let floor_str = format!("{:.1}", floor).replace(".", "pt");
                    format!("{}-spread-{}", base, floor_str)
                } else {
                    format!("{}-spread", base)
                }
            }
            MarketType::Total => {
                if let Some(floor) = market.floor_strike {
                    let floor_str = format!("{:.1}", floor).replace(".", "pt");
                    format!("{}-total-{}", base, floor_str)
                } else {
                    format!("{}-total", base)
                }
            }
            MarketType::Btts => {
                format!("{}-btts", base)
            }
        }
    }

    /// Discover new markets created since a given timestamp
    /// Returns only NEW pairs not already in the known_tickers set
    pub async fn discover_since(
        &self,
        since_ts: u64,
        known_tickers: &std::collections::HashSet<String>,
        leagues: &[&str],
    ) -> DiscoveryResult {
        let configs: Vec<_> = if leagues.is_empty() {
            get_league_configs()
        } else {
            leagues.iter()
                .filter_map(|l| get_league_config(l))
                .collect()
        };

        let mut result = DiscoveryResult::default();

        for config in &configs {
            match self.discover_series_since(config, since_ts, known_tickers).await {
                Ok(pairs) => {
                    if !pairs.is_empty() {
                        tracing::info!("  {} {}: {} new pairs",
                            config.league_code, "discovery", pairs.len());
                    }
                    result.pairs.extend(pairs);
                }
                Err(e) => {
                    result.errors.push(format!("{}: {}", config.league_code, e));
                }
            }
        }

        result.kalshi_events_found = result.pairs.len();
        result.poly_matches = result.pairs.len();
        result
    }

    /// Discover new markets for a single league since timestamp
    async fn discover_series_since(
        &self,
        config: &LeagueConfig,
        since_ts: u64,
        known_tickers: &std::collections::HashSet<String>,
    ) -> Result<Vec<MarketPair>> {
        let mut all_pairs = Vec::new();

        // Check all series for this league
        let series_list: Vec<&str> = [
            Some(config.kalshi_series_game),
            config.kalshi_series_spread,
            config.kalshi_series_total,
            config.kalshi_series_btts,
        ].into_iter().flatten().collect();

        for series in series_list {
            // Rate limit
            {
                let _permit = self.kalshi_semaphore.acquire().await
                    .map_err(|e| anyhow::anyhow!("semaphore closed: {}", e))?;
                self.kalshi_limiter.until_ready().await;
            }

            let markets = match self.kalshi.get_markets_since(series, since_ts).await {
                Ok(m) => m,
                Err(e) => {
                    tracing::warn!("  Failed to query {}: {}", series, e);
                    continue;
                }
            };

            // Filter to only new markets
            let new_markets: Vec<_> = markets.into_iter()
                .filter(|m| !known_tickers.contains(&m.ticker))
                .collect();

            if new_markets.is_empty() {
                continue;
            }

            // Look up on Polymarket in parallel
            let pairs: Vec<MarketPair> = stream::iter(new_markets)
                .map(|market| {
                    async move {
                        self.try_match_market(config, &market).await
                    }
                })
                .buffer_unordered(GAMMA_CONCURRENCY)
                .filter_map(|x| async { x })
                .collect()
                .await;

            all_pairs.extend(pairs);
        }

        Ok(all_pairs)
    }

    /// Try to match a single Kalshi market to Polymarket
    async fn try_match_market(&self, config: &LeagueConfig, market: &KalshiMarket) -> Option<MarketPair> {
        // Extract event ticker from market ticker (format: SERIES-EVENTID-SUFFIX)
        let parts: Vec<&str> = market.ticker.split('-').collect();
        if parts.len() < 2 {
            return None;
        }

        // Reconstruct event ticker (SERIES-EVENTID)
        let event_ticker = format!("{}-{}", parts[0], parts[1]);

        // Determine market type from series
        let market_type = if market.ticker.contains("SPREAD") {
            MarketType::Spread
        } else if market.ticker.contains("TOTAL") {
            MarketType::Total
        } else if market.ticker.contains("BTTS") {
            MarketType::Btts
        } else {
            MarketType::Moneyline
        };

        // Parse event ticker to get teams and date
        let parsed = parse_kalshi_event_ticker(&event_ticker)?;

        // Build poly slug
        let poly_slug = self.build_poly_slug(config.poly_prefix, &parsed, market_type, market);

        // Look up on Polymarket
        let _permit = self.gamma_semaphore.acquire().await.ok()?;
        let (yes_token, no_token) = match self.gamma.lookup_market(&poly_slug).await {
            Ok(Some((yes, no))) => (yes, no),
            Ok(None) => return None,
            Err(e) => {
                tracing::warn!("  ‚ö†Ô∏è Gamma lookup failed for {}: {}", poly_slug, e);
                return None;
            }
        };

        let team_suffix = extract_team_suffix(&market.ticker);

        Some(MarketPair {
            pair_id: format!("{}-{}", poly_slug, market.ticker).into(),
            league: config.league_code.into(),
            market_type,
            description: format!("{}", market.title).into(),
            kalshi_event_ticker: event_ticker.into(),
            kalshi_market_ticker: market.ticker.clone().into(),
            poly_slug: poly_slug.into(),
            poly_yes_token: yes_token.into(),
            poly_no_token: no_token.into(),
            line_value: market.floor_strike,
            team_suffix: team_suffix.map(|s| s.into()),
        })
    }

    /// Discover esports market pairs using series-based name matching
    async fn discover_esports_league(&self, config: &LeagueConfig) -> DiscoveryResult {
        let series_id = match config.poly_series_id {
            Some(id) => id,
            None => return DiscoveryResult::default(),
        };

        info!("üéÆ Discovering {} esports markets (series_id={})...", config.league_code, series_id);

        // Phase 1: Build Polymarket lookup from events
        let poly_events = match self.gamma.fetch_events_by_series(series_id).await {
            Ok(events) => events,
            Err(e) => {
                warn!("Failed to fetch Polymarket events for {}: {}", config.league_code, e);
                return DiscoveryResult {
                    errors: vec![format!("{}: {}", config.league_code, e)],
                    ..Default::default()
                };
            }
        };

        // Build lookup: (date:norm_team1:norm_team2) -> (slug, yes_token, no_token)
        let mut poly_lookup: HashMap<String, (String, String, String)> = HashMap::new();

        for event in &poly_events {
            let slug = match &event.slug {
                Some(s) => s,
                None => continue,
            };

            let title = match &event.title {
                Some(t) => t,
                None => continue,
            };

            if let Some((team1, team2)) = parse_poly_event_title(title) {
                if let Some(date) = extract_date_from_poly_slug(slug) {
                    let norm1 = normalize_esports_team(&team1);
                    let norm2 = normalize_esports_team(&team2);

                    // Find moneyline market (no -game, -total, -map suffix)
                    if let Some(markets) = &event.markets {
                        for market in markets {
                            let market_slug = market.slug.as_deref().unwrap_or("");
                            let is_moneyline = !market_slug.contains("-game")
                                && !market_slug.contains("-total")
                                && !market_slug.contains("-map-")
                                && !market_slug.contains("-handicap");

                            if is_moneyline {
                                if let Some(tokens) = &market.clob_token_ids {
                                    if let Ok(ids) = serde_json::from_str::<Vec<String>>(tokens) {
                                        if ids.len() >= 2 {
                                            let key1 = format!("{}:{}:{}", date, norm1, norm2);
                                            let key2 = format!("{}:{}:{}", date, norm2, norm1);
                                            poly_lookup.insert(key1, (slug.clone(), ids[0].clone(), ids[1].clone()));
                                            poly_lookup.insert(key2, (slug.clone(), ids[0].clone(), ids[1].clone()));
                                        }
                                    }
                                }
                                break;
                            }
                        }
                    }
                }
            }
        }

        info!("  üìä Built {} Polymarket lookup entries", poly_lookup.len() / 2);

        // Phase 2: Fetch and match Kalshi events
        let kalshi_events = {
            let _permit = self.kalshi_semaphore.acquire().await.ok();
            self.kalshi_limiter.until_ready().await;
            match self.kalshi.get_events(config.kalshi_series_game, 50).await {
                Ok(events) => events,
                Err(e) => {
                    warn!("Failed to fetch Kalshi events for {}: {}", config.league_code, e);
                    return DiscoveryResult {
                        errors: vec![format!("{}: {}", config.league_code, e)],
                        ..Default::default()
                    };
                }
            }
        };

        let mut pairs = Vec::new();

        for event in &kalshi_events {
            if let Some((team1, team2)) = parse_esports_kalshi_title(&event.title) {
                if let Some(date) = parse_kalshi_event_ticker(&event.event_ticker)
                    .map(|p| kalshi_date_to_iso(&p.date))
                {
                    let norm1 = normalize_esports_team(&team1);
                    let norm2 = normalize_esports_team(&team2);
                    let key = format!("{}:{}:{}", date, norm1, norm2);

                    if let Some((slug, yes_token, no_token)) = poly_lookup.get(&key) {
                        // Get Kalshi markets for this event
                        let markets = {
                            let _permit = self.kalshi_semaphore.acquire().await.ok();
                            self.kalshi_limiter.until_ready().await;
                            self.kalshi.get_markets(&event.event_ticker).await.unwrap_or_default()
                        };

                        for market in markets {
                            let team_suffix = extract_team_suffix(&market.ticker);

                            pairs.push(MarketPair {
                                pair_id: format!("{}-{}", slug, market.ticker).into(),
                                league: config.league_code.into(),
                                market_type: MarketType::Moneyline,
                                description: format!("{} - {}", event.title, market.title).into(),
                                kalshi_event_ticker: event.event_ticker.clone().into(),
                                kalshi_market_ticker: market.ticker.into(),
                                poly_slug: slug.clone().into(),
                                poly_yes_token: yes_token.clone().into(),
                                poly_no_token: no_token.clone().into(),
                                line_value: market.floor_strike,
                                team_suffix: team_suffix.map(|s| s.into()),
                            });
                        }
                    }
                }
            }
        }

        if !pairs.is_empty() {
            info!("  ‚úÖ {} {}: matched {} pairs", config.league_code, "esports", pairs.len());
        }

        DiscoveryResult {
            pairs,
            kalshi_events_found: kalshi_events.len(),
            poly_matches: poly_lookup.len() / 2,
            poly_misses: 0,
            errors: vec![],
        }
    }
}

// === Helpers ===

/// Filter market pairs by enabled leagues
/// If leagues is empty, returns all pairs (no filtering)
fn filter_pairs_by_leagues(pairs: Vec<MarketPair>, leagues: &[&str]) -> Vec<MarketPair> {
    if leagues.is_empty() {
        return pairs;
    }
    pairs.into_iter()
        .filter(|p| leagues.iter().any(|l| *l == &*p.league))
        .collect()
}

#[derive(Debug, Clone)]
struct ParsedKalshiTicker {
    date: String,  // "25DEC27"
    team1: String, // "CFC"
    team2: String, // "AVL"
}

/// Parse Kalshi event ticker like "KXEPLGAME-25DEC27CFCAVL" or "KXNCAAFGAME-25DEC27M-OHFRES"
fn parse_kalshi_event_ticker(ticker: &str) -> Option<ParsedKalshiTicker> {
    let parts: Vec<&str> = ticker.split('-').collect();
    if parts.len() < 2 {
        return None;
    }

    // Handle two formats:
    // 1. "KXEPLGAME-25DEC27CFCAVL" - date+teams in parts[1]
    // 2. "KXNCAAFGAME-25DEC27M-OHFRES" - date in parts[1], teams in parts[2]
    let (date, teams_part) = if parts.len() >= 3 && parts[2].len() >= 4 {
        // Format 2: 3-part ticker with separate teams section
        // parts[1] is like "25DEC27M" (date + optional suffix)
        let date_part = parts[1];
        let date = if date_part.len() >= 7 {
            date_part[..7].to_uppercase()
        } else {
            return None;
        };
        (date, parts[2])
    } else {
        // Format 1: 2-part ticker with combined date+teams
        let date_teams = parts[1];
        // Minimum: 7 (date) + 2 + 2 (min team codes) = 11
        if date_teams.len() < 11 {
            return None;
        }
        let date = date_teams[..7].to_uppercase();
        let teams = &date_teams[7..];
        (date, teams)
    };

    // Split team codes - try to find the best split point
    // Team codes range from 2-4 chars (e.g., OM, CFC, FRES)
    let (team1, team2) = split_team_codes(teams_part);

    Some(ParsedKalshiTicker { date, team1, team2 })
}

/// Split a combined team string into two team codes
/// Tries multiple split strategies based on string length
fn split_team_codes(teams: &str) -> (String, String) {
    let len = teams.len();

    // For 6 chars, could be 3+3, 2+4, or 4+2
    // For 5 chars, could be 2+3 or 3+2
    // For 4 chars, must be 2+2
    // For 7 chars, could be 3+4 or 4+3
    // For 8 chars, could be 4+4, 3+5, 5+3

    match len {
        4 => (teams[..2].to_uppercase(), teams[2..].to_uppercase()),
        5 => {
            // Prefer 2+3 (common for OM+ASM, OL+PSG)
            (teams[..2].to_uppercase(), teams[2..].to_uppercase())
        }
        6 => {
            // Check if it looks like 2+4 pattern (e.g., OHFRES = OH+FRES)
            // Common 2-letter codes: OM, OL, OH, SF, LA, NY, KC, TB, etc.
            let first_two = &teams[..2].to_uppercase();
            if is_likely_two_letter_code(first_two) {
                (first_two.clone(), teams[2..].to_uppercase())
            } else {
                // Default to 3+3
                (teams[..3].to_uppercase(), teams[3..].to_uppercase())
            }
        }
        7 => {
            // Could be 3+4 or 4+3 - prefer 3+4
            (teams[..3].to_uppercase(), teams[3..].to_uppercase())
        }
        _ if len >= 8 => {
            // 4+4 or longer
            (teams[..4].to_uppercase(), teams[4..].to_uppercase())
        }
        _ => {
            let mid = len / 2;
            (teams[..mid].to_uppercase(), teams[mid..].to_uppercase())
        }
    }
}

/// Check if a 2-letter code is a known/likely team abbreviation
fn is_likely_two_letter_code(code: &str) -> bool {
    matches!(
        code,
        // European football (Ligue 1, etc.)
        "OM" | "OL" | "FC" |
        // US sports common abbreviations
        "OH" | "SF" | "LA" | "NY" | "KC" | "TB" | "GB" | "NE" | "NO" | "LV" |
        // Generic short codes
        "BC" | "SC" | "AC" | "AS" | "US"
    )
}

/// Convert Kalshi date "25DEC27" to ISO "2025-12-27"
fn kalshi_date_to_iso(kalshi_date: &str) -> String {
    if kalshi_date.len() != 7 {
        return kalshi_date.to_string();
    }
    
    let year = format!("20{}", &kalshi_date[..2]);
    let month = match &kalshi_date[2..5].to_uppercase()[..] {
        "JAN" => "01", "FEB" => "02", "MAR" => "03", "APR" => "04",
        "MAY" => "05", "JUN" => "06", "JUL" => "07", "AUG" => "08",
        "SEP" => "09", "OCT" => "10", "NOV" => "11", "DEC" => "12",
        _ => "01",
    };
    let day = &kalshi_date[5..7];
    
    format!("{}-{}-{}", year, month, day)
}

/// Extract team suffix from market ticker (e.g., "KXEPLGAME-25DEC27CFCAVL-CFC" -> "CFC")
fn extract_team_suffix(ticker: &str) -> Option<String> {
    let mut splits = ticker.splitn(3, '-');
    splits.next()?; // series
    splits.next()?; // event
    splits.next().map(|s| s.to_uppercase())
}

// === Esports Discovery Helpers ===

// Static regex patterns compiled once for performance (avoids recompilation on each call)
static RE_ESPORTS_SUFFIX: LazyLock<Regex> = LazyLock::new(|| {
    Regex::new(r"(?i)\s*(esports|gaming|team|clan)\s*$").unwrap()
});
static RE_ESPORTS_PREFIX: LazyLock<Regex> = LazyLock::new(|| {
    Regex::new(r"(?i)^(team|clan)\s+").unwrap()
});
static RE_POLY_TITLE_PARENS: LazyLock<Regex> = LazyLock::new(|| {
    Regex::new(r"(?i):\s*(.+?)\s+vs\.?\s+(.+?)\s*\(").unwrap()
});
static RE_POLY_TITLE_DASH: LazyLock<Regex> = LazyLock::new(|| {
    Regex::new(r"(?i):\s*(.+?)\s+vs\.?\s+(.+?)\s*-").unwrap()
});
static RE_POLY_TITLE_FALLBACK: LazyLock<Regex> = LazyLock::new(|| {
    Regex::new(r"(?i)(.+?)\s+vs\.?\s+(.+?)(?:\s*\(|\s*-|$)").unwrap()
});
static RE_KALSHI_TITLE_COLON: LazyLock<Regex> = LazyLock::new(|| {
    Regex::new(r"(?i):\s*(.+?)\s+vs\.?\s+(.+)$").unwrap()
});
static RE_KALSHI_TITLE_FALLBACK: LazyLock<Regex> = LazyLock::new(|| {
    Regex::new(r"(?i)(.+?)\s+vs\.?\s+(.+)$").unwrap()
});

/// Normalize esports team name for matching
/// "FURIA Esports" -> "furia", "Cloud9 New York" -> "cloud9-new-york"
fn normalize_esports_team(name: &str) -> String {
    // Convert to lowercase first, then remove common suffixes and prefixes
    let lower = name.to_lowercase();

    // Remove common suffixes (at the end)
    let cleaned = RE_ESPORTS_SUFFIX.replace(&lower, "").to_string();

    // Remove common prefixes (at the start, like "Team Liquid" -> "Liquid")
    let cleaned = RE_ESPORTS_PREFIX.replace(&cleaned, "").to_string();

    // Also remove periods and apostrophes
    let cleaned = cleaned.replace(".", "").replace("'", "");

    // Join words with hyphens
    cleaned.split_whitespace().collect::<Vec<_>>().join("-")
}

/// Parse Polymarket event title to extract team names
/// "Counter-Strike: Team1 vs Team2 (BO3)" -> Some((team1, team2))
fn parse_poly_event_title(title: &str) -> Option<(String, String)> {
    // Helper to extract teams from captures
    fn extract_teams(caps: &regex::Captures) -> Option<(String, String)> {
        Some((
            caps.get(1)?.as_str().trim().to_string(),
            caps.get(2)?.as_str().trim().to_string(),
        ))
    }

    // Pattern: "Game: Team1 vs Team2 (BON)"
    if let Some(caps) = RE_POLY_TITLE_PARENS.captures(title) {
        if let Some(teams) = extract_teams(&caps) {
            return Some(teams);
        }
    }

    // Fallback: "Game: Team1 vs Team2 - Tournament"
    if let Some(caps) = RE_POLY_TITLE_DASH.captures(title) {
        if let Some(teams) = extract_teams(&caps) {
            return Some(teams);
        }
    }

    // Final fallback: just "Team1 vs Team2" without colon prefix
    if let Some(caps) = RE_POLY_TITLE_FALLBACK.captures(title) {
        if let Some(teams) = extract_teams(&caps) {
            return Some(teams);
        }
    }

    None
}

/// Extract date from Polymarket slug
/// "cs2-team1-team2-2026-01-16" -> Some("2026-01-16")
fn extract_date_from_poly_slug(slug: &str) -> Option<String> {
    let parts: Vec<&str> = slug.split('-').collect();
    if parts.len() >= 4 {
        let year = parts[parts.len() - 3];
        let month = parts[parts.len() - 2];
        let day = parts[parts.len() - 1];

        if year.len() == 4 && month.len() == 2 && day.len() == 2 {
            return Some(format!("{}-{}-{}", year, month, day));
        }
    }
    None
}

/// Parse Kalshi esports event title
/// "Tournament: Team1 vs. Team2" -> Some((team1, team2))
fn parse_esports_kalshi_title(title: &str) -> Option<(String, String)> {
    // Helper to extract teams from captures
    fn extract_teams(caps: &regex::Captures) -> Option<(String, String)> {
        Some((
            caps.get(1)?.as_str().trim().to_string(),
            caps.get(2)?.as_str().trim().to_string(),
        ))
    }

    // Pattern: "Tournament: Team1 vs. Team2"
    if let Some(caps) = RE_KALSHI_TITLE_COLON.captures(title) {
        if let Some(teams) = extract_teams(&caps) {
            return Some(teams);
        }
    }

    // Fallback: just "Team1 vs Team2"
    if let Some(caps) = RE_KALSHI_TITLE_FALLBACK.captures(title) {
        if let Some(teams) = extract_teams(&caps) {
            return Some(teams);
        }
    }

    None
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_kalshi_ticker() {
        let parsed = parse_kalshi_event_ticker("KXEPLGAME-25DEC27CFCAVL").unwrap();
        assert_eq!(parsed.date, "25DEC27");
        assert_eq!(parsed.team1, "CFC");
        assert_eq!(parsed.team2, "AVL");
    }

    #[test]
    fn test_kalshi_date_to_iso() {
        assert_eq!(kalshi_date_to_iso("25DEC27"), "2025-12-27");
        assert_eq!(kalshi_date_to_iso("25JAN01"), "2025-01-01");
    }

    #[test]
    fn test_normalize_esports_team() {
        assert_eq!(normalize_esports_team("FURIA Esports"), "furia");
        assert_eq!(normalize_esports_team("Cloud9 New York"), "cloud9-new-york");
        assert_eq!(normalize_esports_team("Team Liquid"), "liquid");
        assert_eq!(normalize_esports_team("G2"), "g2");
        assert_eq!(normalize_esports_team("BetBoom Team"), "betboom");
        assert_eq!(normalize_esports_team("Gen.G"), "geng");
    }

    #[test]
    fn test_parse_poly_event_title() {
        let (t1, t2) = parse_poly_event_title("Counter-Strike: FURIA vs 9INE (BO3)").unwrap();
        assert_eq!(t1, "FURIA");
        assert_eq!(t2, "9INE");

        let (t1, t2) = parse_poly_event_title("LoL: T1 vs DRX (BO5) - LCK Finals").unwrap();
        assert_eq!(t1, "T1");
        assert_eq!(t2, "DRX");
    }

    #[test]
    fn test_extract_date_from_poly_slug() {
        assert_eq!(
            extract_date_from_poly_slug("cs2-furia-9ine-2026-01-16"),
            Some("2026-01-16".to_string())
        );
        assert_eq!(
            extract_date_from_poly_slug("lol-t1-drx-2026-01-18"),
            Some("2026-01-18".to_string())
        );
        assert_eq!(extract_date_from_poly_slug("invalid"), None);
    }

    #[test]
    fn test_parse_esports_kalshi_title() {
        let (t1, t2) = parse_esports_kalshi_title("BLAST Bounty 2026: FURIA vs. 9INE").unwrap();
        assert_eq!(t1, "FURIA");
        assert_eq!(t2, "9INE");
    }
}
